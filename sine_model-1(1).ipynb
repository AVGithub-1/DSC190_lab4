{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkV-mT56eG_G",
        "outputId": "67dea0d8-f09e-495b-b425-042ceb21787d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "S_hzJMSZeH1Z"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzwhH653eKAB",
        "outputId": "150b5462-634d-4278-f468-9e1acf782294"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numpy 1.23.5\n",
            "TensorFlow 2.10.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "unknown option --versions\n",
            "usage: python [option] ... [-c cmd | -m mod | file | -] [arg] ...\n",
            "Try `python -h' for more information.\n"
          ]
        }
      ],
      "source": [
        "# Print versions\n",
        "!python --versions\n",
        "print('Numpy ' + np.__version__)\n",
        "print('TensorFlow ' + tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "folder = './Data_190-1/Data/'\n",
        "a = pd.read_csv(folder + 'apple.csv')\n",
        "a['Fruit'] = 0\n",
        "b = pd.read_csv(folder + 'banana.csv')\n",
        "b['Fruit'] = 1\n",
        "o = pd.read_csv(folder + 'orange.csv')\n",
        "o['Fruit'] = 2\n",
        "all_data = pd.concat([a,b,o], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Red</th>\n",
              "      <th>Green</th>\n",
              "      <th>Blue</th>\n",
              "      <th>Fruit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.522</td>\n",
              "      <td>0.261</td>\n",
              "      <td>0.217</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.522</td>\n",
              "      <td>0.261</td>\n",
              "      <td>0.217</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.550</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.545</td>\n",
              "      <td>0.227</td>\n",
              "      <td>0.227</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.556</td>\n",
              "      <td>0.222</td>\n",
              "      <td>0.222</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>0.590</td>\n",
              "      <td>0.282</td>\n",
              "      <td>0.128</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>0.605</td>\n",
              "      <td>0.279</td>\n",
              "      <td>0.116</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>0.595</td>\n",
              "      <td>0.286</td>\n",
              "      <td>0.119</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>0.583</td>\n",
              "      <td>0.292</td>\n",
              "      <td>0.125</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>0.518</td>\n",
              "      <td>0.304</td>\n",
              "      <td>0.179</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>256 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Red  Green   Blue  Fruit\n",
              "0    0.522  0.261  0.217      0\n",
              "1    0.522  0.261  0.217      0\n",
              "2    0.550  0.250  0.200      0\n",
              "3    0.545  0.227  0.227      0\n",
              "4    0.556  0.222  0.222      0\n",
              "..     ...    ...    ...    ...\n",
              "251  0.590  0.282  0.128      2\n",
              "252  0.605  0.279  0.116      2\n",
              "253  0.595  0.286  0.119      2\n",
              "254  0.583  0.292  0.125      2\n",
              "255  0.518  0.304  0.179      2\n",
              "\n",
              "[256 rows x 4 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Yvg11fnSeL2j"
      },
      "outputs": [],
      "source": [
        "# Settings\n",
        "nsamples = len(all_data)     # Number of samples to use as a dataset\n",
        "val_ratio = 0.2     # Percentage of samples that should be held for validation set\n",
        "test_ratio = 0.2    # Percentage of samples that should be held for test set\n",
        "tflite_model_name = 'fruit_model'  # Will be given .tflite suffix\n",
        "c_model_name = 'fruit_model'       # Will be given .h suffix\n",
        "np.random.seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "#shuffle all_data \n",
        "all_data = all_data.sample(frac=1)\n",
        "\n",
        "#separate all_data into the x_values(features) and y_values(labels)\n",
        "\n",
        "x_values = all_data.drop(['Fruit'], axis=1)\n",
        "y_values = all_data['Fruit']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "HMpnyGbtehmJ",
        "outputId": "04b6018c-f046-409e-c4eb-2a5007c0e6c7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plit the dataset into training, validation, and test sets\n",
        "val_split = int(val_ratio * nsamples)\n",
        "test_split = int(val_split + (test_ratio * nsamples))\n",
        "x_val, x_test, x_train = np.split(x_values, [val_split, test_split])\n",
        "y_val, y_test, y_train = np.split(y_values, [val_split, test_split])\n",
        "\n",
        "# Check that our splits add up correctly\n",
        "assert(x_train.size + x_val.size + x_test.size) == nsamples*3\n",
        "\n",
        "# Plot the data in each partition in different colors:\n",
        "plt.plot(x_train, y_train, 'b.', label=\"Train\")\n",
        "plt.plot(x_test, y_test, 'r.', label=\"Test\")\n",
        "plt.plot(x_val, y_val, 'y.', label=\"Validate\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gWFrCgynejS0"
      },
      "outputs": [],
      "source": [
        "# Create a model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(3,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUwkcbKqelkj",
        "outputId": "e2d7251e-8189-4ed8-c692-b506cd7cb0b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 16)                64        \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 625\n",
            "Trainable params: 625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# View model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "f9IulTsjenrW"
      },
      "outputs": [],
      "source": [
        "# Add optimizer, loss function, and metrics to model and compile it\n",
        "model.compile(optimizer='adam', loss='mae', metrics=['mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPMAZYEWepy6",
        "outputId": "86a3fb87-eec3-4115-a6b5-19308b3cc891"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 2s 461ms/step - loss: 1.2572 - mae: 1.2572 - val_loss: 1.0972 - val_mae: 1.0972\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1.2339 - mae: 1.2339 - val_loss: 1.0748 - val_mae: 1.0748\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 1.2113 - mae: 1.2113 - val_loss: 1.0539 - val_mae: 1.0539\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 1.1902 - mae: 1.1902 - val_loss: 1.0352 - val_mae: 1.0352\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 1.1704 - mae: 1.1704 - val_loss: 1.0181 - val_mae: 1.0181\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 141ms/step - loss: 1.1521 - mae: 1.1521 - val_loss: 1.0021 - val_mae: 1.0021\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 153ms/step - loss: 1.1355 - mae: 1.1355 - val_loss: 0.9881 - val_mae: 0.9881\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 1.1205 - mae: 1.1205 - val_loss: 0.9766 - val_mae: 0.9766\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.1090 - mae: 1.1090 - val_loss: 0.9691 - val_mae: 0.9691\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1.1019 - mae: 1.1019 - val_loss: 0.9649 - val_mae: 0.9649\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 1.0966 - mae: 1.0966 - val_loss: 0.9608 - val_mae: 0.9608\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 1.0913 - mae: 1.0913 - val_loss: 0.9568 - val_mae: 0.9568\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1.0859 - mae: 1.0859 - val_loss: 0.9526 - val_mae: 0.9526\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1.0798 - mae: 1.0798 - val_loss: 0.9483 - val_mae: 0.9483\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1.0742 - mae: 1.0742 - val_loss: 0.9436 - val_mae: 0.9436\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 1.0677 - mae: 1.0677 - val_loss: 0.9391 - val_mae: 0.9391\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 1.0619 - mae: 1.0619 - val_loss: 0.9350 - val_mae: 0.9350\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 1.0571 - mae: 1.0571 - val_loss: 0.9309 - val_mae: 0.9309\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 143ms/step - loss: 1.0523 - mae: 1.0523 - val_loss: 0.9270 - val_mae: 0.9270\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1.0479 - mae: 1.0479 - val_loss: 0.9229 - val_mae: 0.9229\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1.0433 - mae: 1.0433 - val_loss: 0.9189 - val_mae: 0.9189\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1.0387 - mae: 1.0387 - val_loss: 0.9147 - val_mae: 0.9147\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.0339 - mae: 1.0339 - val_loss: 0.9104 - val_mae: 0.9104\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1.0292 - mae: 1.0292 - val_loss: 0.9060 - val_mae: 0.9060\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 1.0241 - mae: 1.0241 - val_loss: 0.9015 - val_mae: 0.9015\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 1.0190 - mae: 1.0190 - val_loss: 0.8969 - val_mae: 0.8969\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1.0142 - mae: 1.0142 - val_loss: 0.8922 - val_mae: 0.8922\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 1.0089 - mae: 1.0089 - val_loss: 0.8875 - val_mae: 0.8875\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 1.0034 - mae: 1.0034 - val_loss: 0.8827 - val_mae: 0.8827\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.9982 - mae: 0.9982 - val_loss: 0.8778 - val_mae: 0.8778\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.9926 - mae: 0.9926 - val_loss: 0.8727 - val_mae: 0.8727\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.9865 - mae: 0.9865 - val_loss: 0.8673 - val_mae: 0.8673\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.9805 - mae: 0.9805 - val_loss: 0.8617 - val_mae: 0.8617\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.9742 - mae: 0.9742 - val_loss: 0.8558 - val_mae: 0.8558\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.9672 - mae: 0.9672 - val_loss: 0.8498 - val_mae: 0.8498\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.9605 - mae: 0.9605 - val_loss: 0.8435 - val_mae: 0.8435\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.9533 - mae: 0.9533 - val_loss: 0.8371 - val_mae: 0.8371\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.9458 - mae: 0.9458 - val_loss: 0.8304 - val_mae: 0.8304\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.9382 - mae: 0.9382 - val_loss: 0.8234 - val_mae: 0.8234\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.9301 - mae: 0.9301 - val_loss: 0.8162 - val_mae: 0.8162\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.9215 - mae: 0.9215 - val_loss: 0.8086 - val_mae: 0.8086\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.9129 - mae: 0.9129 - val_loss: 0.8007 - val_mae: 0.8007\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.9038 - mae: 0.9038 - val_loss: 0.7923 - val_mae: 0.7923\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.8938 - mae: 0.8938 - val_loss: 0.7835 - val_mae: 0.7835\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.8846 - mae: 0.8846 - val_loss: 0.7742 - val_mae: 0.7742\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.8733 - mae: 0.8733 - val_loss: 0.7645 - val_mae: 0.7645\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.8631 - mae: 0.8631 - val_loss: 0.7543 - val_mae: 0.7543\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.8507 - mae: 0.8507 - val_loss: 0.7439 - val_mae: 0.7439\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.8391 - mae: 0.8391 - val_loss: 0.7329 - val_mae: 0.7329\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.8267 - mae: 0.8267 - val_loss: 0.7215 - val_mae: 0.7215\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 155ms/step - loss: 0.8145 - mae: 0.8145 - val_loss: 0.7098 - val_mae: 0.7098\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.8014 - mae: 0.8014 - val_loss: 0.6976 - val_mae: 0.6976\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.7860 - mae: 0.7860 - val_loss: 0.6851 - val_mae: 0.6851\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.7721 - mae: 0.7721 - val_loss: 0.6718 - val_mae: 0.6718\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.7579 - mae: 0.7579 - val_loss: 0.6579 - val_mae: 0.6579\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.7409 - mae: 0.7409 - val_loss: 0.6436 - val_mae: 0.6436\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.7251 - mae: 0.7251 - val_loss: 0.6286 - val_mae: 0.6286\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.7066 - mae: 0.7066 - val_loss: 0.6129 - val_mae: 0.6129\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.6915 - mae: 0.6915 - val_loss: 0.5966 - val_mae: 0.5966\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.6700 - mae: 0.6700 - val_loss: 0.5798 - val_mae: 0.5798\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 148ms/step - loss: 0.6529 - mae: 0.6529 - val_loss: 0.5789 - val_mae: 0.5789\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.6503 - mae: 0.6503 - val_loss: 0.5868 - val_mae: 0.5868\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.6546 - mae: 0.6546 - val_loss: 0.5911 - val_mae: 0.5911\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6553 - mae: 0.6553 - val_loss: 0.5922 - val_mae: 0.5922\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6557 - mae: 0.6557 - val_loss: 0.5916 - val_mae: 0.5916\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.6545 - mae: 0.6545 - val_loss: 0.5885 - val_mae: 0.5885\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.6521 - mae: 0.6521 - val_loss: 0.5836 - val_mae: 0.5836\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.6490 - mae: 0.6490 - val_loss: 0.5769 - val_mae: 0.5769\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.6450 - mae: 0.6450 - val_loss: 0.5690 - val_mae: 0.5690\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.6404 - mae: 0.6404 - val_loss: 0.5690 - val_mae: 0.5690\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6419 - mae: 0.6419 - val_loss: 0.5711 - val_mae: 0.5711\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.6433 - mae: 0.6433 - val_loss: 0.5689 - val_mae: 0.5689\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.6407 - mae: 0.6407 - val_loss: 0.5650 - val_mae: 0.5650\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.6373 - mae: 0.6373 - val_loss: 0.5667 - val_mae: 0.5667\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.6378 - mae: 0.6378 - val_loss: 0.5676 - val_mae: 0.5676\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.6376 - mae: 0.6376 - val_loss: 0.5661 - val_mae: 0.5661\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.6361 - mae: 0.6361 - val_loss: 0.5630 - val_mae: 0.5630\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.6342 - mae: 0.6342 - val_loss: 0.5633 - val_mae: 0.5633\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.6341 - mae: 0.6341 - val_loss: 0.5630 - val_mae: 0.5630\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.6331 - mae: 0.6331 - val_loss: 0.5613 - val_mae: 0.5613\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.6319 - mae: 0.6319 - val_loss: 0.5621 - val_mae: 0.5621\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6316 - mae: 0.6316 - val_loss: 0.5613 - val_mae: 0.5613\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6305 - mae: 0.6305 - val_loss: 0.5596 - val_mae: 0.5596\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.6294 - mae: 0.6294 - val_loss: 0.5596 - val_mae: 0.5596\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 0.6289 - mae: 0.6289 - val_loss: 0.5584 - val_mae: 0.5584\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6274 - mae: 0.6274 - val_loss: 0.5580 - val_mae: 0.5580\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.6267 - mae: 0.6267 - val_loss: 0.5586 - val_mae: 0.5586\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.6264 - mae: 0.6264 - val_loss: 0.5573 - val_mae: 0.5573\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.6250 - mae: 0.6250 - val_loss: 0.5564 - val_mae: 0.5564\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 141ms/step - loss: 0.6241 - mae: 0.6241 - val_loss: 0.5560 - val_mae: 0.5560\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.6234 - mae: 0.6234 - val_loss: 0.5547 - val_mae: 0.5547\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.6225 - mae: 0.6225 - val_loss: 0.5544 - val_mae: 0.5544\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6217 - mae: 0.6217 - val_loss: 0.5534 - val_mae: 0.5534\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6206 - mae: 0.6206 - val_loss: 0.5526 - val_mae: 0.5526\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6200 - mae: 0.6200 - val_loss: 0.5521 - val_mae: 0.5521\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.6191 - mae: 0.6191 - val_loss: 0.5513 - val_mae: 0.5513\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6180 - mae: 0.6180 - val_loss: 0.5508 - val_mae: 0.5508\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.6174 - mae: 0.6174 - val_loss: 0.5502 - val_mae: 0.5502\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6164 - mae: 0.6164 - val_loss: 0.5497 - val_mae: 0.5497\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6156 - mae: 0.6156 - val_loss: 0.5492 - val_mae: 0.5492\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6146 - mae: 0.6146 - val_loss: 0.5483 - val_mae: 0.5483\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.6138 - mae: 0.6138 - val_loss: 0.5474 - val_mae: 0.5474\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.6129 - mae: 0.6129 - val_loss: 0.5465 - val_mae: 0.5465\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.6119 - mae: 0.6119 - val_loss: 0.5457 - val_mae: 0.5457\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.6110 - mae: 0.6110 - val_loss: 0.5448 - val_mae: 0.5448\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.6101 - mae: 0.6101 - val_loss: 0.5438 - val_mae: 0.5438\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.6092 - mae: 0.6092 - val_loss: 0.5431 - val_mae: 0.5431\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.6082 - mae: 0.6082 - val_loss: 0.5422 - val_mae: 0.5422\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.6071 - mae: 0.6071 - val_loss: 0.5414 - val_mae: 0.5414\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.6061 - mae: 0.6061 - val_loss: 0.5404 - val_mae: 0.5404\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.6050 - mae: 0.6050 - val_loss: 0.5394 - val_mae: 0.5394\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.6040 - mae: 0.6040 - val_loss: 0.5383 - val_mae: 0.5383\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.6029 - mae: 0.6029 - val_loss: 0.5371 - val_mae: 0.5371\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.6018 - mae: 0.6018 - val_loss: 0.5360 - val_mae: 0.5360\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.6006 - mae: 0.6006 - val_loss: 0.5351 - val_mae: 0.5351\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.5995 - mae: 0.5995 - val_loss: 0.5342 - val_mae: 0.5342\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.5983 - mae: 0.5983 - val_loss: 0.5333 - val_mae: 0.5333\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 195ms/step - loss: 0.5972 - mae: 0.5972 - val_loss: 0.5324 - val_mae: 0.5324\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.5960 - mae: 0.5960 - val_loss: 0.5313 - val_mae: 0.5313\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5946 - mae: 0.5946 - val_loss: 0.5301 - val_mae: 0.5301\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.5933 - mae: 0.5933 - val_loss: 0.5290 - val_mae: 0.5290\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5920 - mae: 0.5920 - val_loss: 0.5278 - val_mae: 0.5278\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.5907 - mae: 0.5907 - val_loss: 0.5268 - val_mae: 0.5268\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5894 - mae: 0.5894 - val_loss: 0.5253 - val_mae: 0.5253\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.5879 - mae: 0.5879 - val_loss: 0.5238 - val_mae: 0.5238\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.5866 - mae: 0.5866 - val_loss: 0.5227 - val_mae: 0.5227\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.5853 - mae: 0.5853 - val_loss: 0.5214 - val_mae: 0.5214\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.5838 - mae: 0.5838 - val_loss: 0.5202 - val_mae: 0.5202\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.5821 - mae: 0.5821 - val_loss: 0.5192 - val_mae: 0.5192\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.5807 - mae: 0.5807 - val_loss: 0.5178 - val_mae: 0.5178\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.5790 - mae: 0.5790 - val_loss: 0.5162 - val_mae: 0.5162\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.5776 - mae: 0.5776 - val_loss: 0.5149 - val_mae: 0.5149\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.5757 - mae: 0.5757 - val_loss: 0.5132 - val_mae: 0.5132\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.5744 - mae: 0.5744 - val_loss: 0.5115 - val_mae: 0.5115\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.5726 - mae: 0.5726 - val_loss: 0.5098 - val_mae: 0.5098\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.5708 - mae: 0.5708 - val_loss: 0.5080 - val_mae: 0.5080\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5692 - mae: 0.5692 - val_loss: 0.5061 - val_mae: 0.5061\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5676 - mae: 0.5676 - val_loss: 0.5045 - val_mae: 0.5045\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5659 - mae: 0.5659 - val_loss: 0.5028 - val_mae: 0.5028\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5637 - mae: 0.5637 - val_loss: 0.5017 - val_mae: 0.5017\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5619 - mae: 0.5619 - val_loss: 0.5009 - val_mae: 0.5009\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5600 - mae: 0.5600 - val_loss: 0.4996 - val_mae: 0.4996\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5579 - mae: 0.5579 - val_loss: 0.4978 - val_mae: 0.4978\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.5561 - mae: 0.5561 - val_loss: 0.4959 - val_mae: 0.4959\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 106ms/step - loss: 0.5540 - mae: 0.5540 - val_loss: 0.4939 - val_mae: 0.4939\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.5519 - mae: 0.5519 - val_loss: 0.4919 - val_mae: 0.4919\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.5500 - mae: 0.5500 - val_loss: 0.4899 - val_mae: 0.4899\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.5475 - mae: 0.5475 - val_loss: 0.4884 - val_mae: 0.4884\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5458 - mae: 0.5458 - val_loss: 0.4862 - val_mae: 0.4862\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5429 - mae: 0.5429 - val_loss: 0.4843 - val_mae: 0.4843\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5409 - mae: 0.5409 - val_loss: 0.4824 - val_mae: 0.4824\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5386 - mae: 0.5386 - val_loss: 0.4797 - val_mae: 0.4797\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5358 - mae: 0.5358 - val_loss: 0.4769 - val_mae: 0.4769\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5334 - mae: 0.5334 - val_loss: 0.4750 - val_mae: 0.4750\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.5311 - mae: 0.5311 - val_loss: 0.4724 - val_mae: 0.4724\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.5279 - mae: 0.5279 - val_loss: 0.4713 - val_mae: 0.4713\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.5261 - mae: 0.5261 - val_loss: 0.4698 - val_mae: 0.4698\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.5235 - mae: 0.5235 - val_loss: 0.4673 - val_mae: 0.4673\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.5202 - mae: 0.5202 - val_loss: 0.4648 - val_mae: 0.4648\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.5180 - mae: 0.5180 - val_loss: 0.4623 - val_mae: 0.4623\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.5142 - mae: 0.5142 - val_loss: 0.4597 - val_mae: 0.4597\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.5122 - mae: 0.5122 - val_loss: 0.4577 - val_mae: 0.4577\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5094 - mae: 0.5094 - val_loss: 0.4547 - val_mae: 0.4547\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.5059 - mae: 0.5059 - val_loss: 0.4512 - val_mae: 0.4512\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5029 - mae: 0.5029 - val_loss: 0.4487 - val_mae: 0.4487\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4991 - mae: 0.4991 - val_loss: 0.4459 - val_mae: 0.4459\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 181ms/step - loss: 0.4963 - mae: 0.4963 - val_loss: 0.4440 - val_mae: 0.4440\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.4931 - mae: 0.4931 - val_loss: 0.4412 - val_mae: 0.4412\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4897 - mae: 0.4897 - val_loss: 0.4380 - val_mae: 0.4380\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4861 - mae: 0.4861 - val_loss: 0.4348 - val_mae: 0.4348\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.4827 - mae: 0.4827 - val_loss: 0.4310 - val_mae: 0.4310\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.4789 - mae: 0.4789 - val_loss: 0.4271 - val_mae: 0.4271\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4750 - mae: 0.4750 - val_loss: 0.4238 - val_mae: 0.4238\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4714 - mae: 0.4714 - val_loss: 0.4202 - val_mae: 0.4202\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4675 - mae: 0.4675 - val_loss: 0.4170 - val_mae: 0.4170\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4636 - mae: 0.4636 - val_loss: 0.4139 - val_mae: 0.4139\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4594 - mae: 0.4594 - val_loss: 0.4110 - val_mae: 0.4110\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4552 - mae: 0.4552 - val_loss: 0.4072 - val_mae: 0.4072\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.4509 - mae: 0.4509 - val_loss: 0.4035 - val_mae: 0.4035\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4465 - mae: 0.4465 - val_loss: 0.3992 - val_mae: 0.3992\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4420 - mae: 0.4420 - val_loss: 0.3951 - val_mae: 0.3951\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.4374 - mae: 0.4374 - val_loss: 0.3912 - val_mae: 0.3912\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.4326 - mae: 0.4326 - val_loss: 0.3876 - val_mae: 0.3876\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4279 - mae: 0.4279 - val_loss: 0.3839 - val_mae: 0.3839\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4231 - mae: 0.4231 - val_loss: 0.3803 - val_mae: 0.3803\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4178 - mae: 0.4178 - val_loss: 0.3754 - val_mae: 0.3754\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4123 - mae: 0.4123 - val_loss: 0.3700 - val_mae: 0.3700\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.4070 - mae: 0.4070 - val_loss: 0.3644 - val_mae: 0.3644\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.4016 - mae: 0.4016 - val_loss: 0.3595 - val_mae: 0.3595\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3960 - mae: 0.3960 - val_loss: 0.3553 - val_mae: 0.3553\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.3902 - mae: 0.3902 - val_loss: 0.3503 - val_mae: 0.3503\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.3840 - mae: 0.3840 - val_loss: 0.3465 - val_mae: 0.3465\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.3789 - mae: 0.3789 - val_loss: 0.3414 - val_mae: 0.3414\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.3729 - mae: 0.3729 - val_loss: 0.3342 - val_mae: 0.3342\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.3656 - mae: 0.3656 - val_loss: 0.3279 - val_mae: 0.3279\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.3593 - mae: 0.3593 - val_loss: 0.3223 - val_mae: 0.3223\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.3532 - mae: 0.3532 - val_loss: 0.3165 - val_mae: 0.3165\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.3466 - mae: 0.3466 - val_loss: 0.3102 - val_mae: 0.3102\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.3393 - mae: 0.3393 - val_loss: 0.3045 - val_mae: 0.3045\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.3328 - mae: 0.3328 - val_loss: 0.2994 - val_mae: 0.2994\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.3249 - mae: 0.3249 - val_loss: 0.2949 - val_mae: 0.2949\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.3186 - mae: 0.3186 - val_loss: 0.2902 - val_mae: 0.2902\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.3127 - mae: 0.3127 - val_loss: 0.2847 - val_mae: 0.2847\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3046 - mae: 0.3046 - val_loss: 0.2799 - val_mae: 0.2799\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.3028 - mae: 0.3028 - val_loss: 0.2756 - val_mae: 0.2756\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.2945 - mae: 0.2945 - val_loss: 0.2699 - val_mae: 0.2699\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2916 - mae: 0.2916 - val_loss: 0.2658 - val_mae: 0.2658\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2849 - mae: 0.2849 - val_loss: 0.2578 - val_mae: 0.2578\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 0.2780 - mae: 0.2780 - val_loss: 0.2490 - val_mae: 0.2490\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.2730 - mae: 0.2730 - val_loss: 0.2418 - val_mae: 0.2418\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.2667 - mae: 0.2667 - val_loss: 0.2337 - val_mae: 0.2337\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.2603 - mae: 0.2603 - val_loss: 0.2269 - val_mae: 0.2269\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.2552 - mae: 0.2552 - val_loss: 0.2210 - val_mae: 0.2210\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.2505 - mae: 0.2505 - val_loss: 0.2154 - val_mae: 0.2154\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2459 - mae: 0.2459 - val_loss: 0.2119 - val_mae: 0.2119\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.2422 - mae: 0.2422 - val_loss: 0.2084 - val_mae: 0.2084\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.2385 - mae: 0.2385 - val_loss: 0.2052 - val_mae: 0.2052\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2340 - mae: 0.2340 - val_loss: 0.2032 - val_mae: 0.2032\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2301 - mae: 0.2301 - val_loss: 0.2035 - val_mae: 0.2035\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.2262 - mae: 0.2262 - val_loss: 0.2049 - val_mae: 0.2049\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.2233 - mae: 0.2233 - val_loss: 0.2054 - val_mae: 0.2054\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.2216 - mae: 0.2216 - val_loss: 0.2039 - val_mae: 0.2039\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.2189 - mae: 0.2189 - val_loss: 0.2005 - val_mae: 0.2005\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.2157 - mae: 0.2157 - val_loss: 0.1960 - val_mae: 0.1960\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.2134 - mae: 0.2134 - val_loss: 0.1930 - val_mae: 0.1930\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.2111 - mae: 0.2111 - val_loss: 0.1898 - val_mae: 0.1898\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.2103 - mae: 0.2103 - val_loss: 0.1884 - val_mae: 0.1884\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.2075 - mae: 0.2075 - val_loss: 0.1887 - val_mae: 0.1887\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.2050 - mae: 0.2050 - val_loss: 0.1890 - val_mae: 0.1890\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.2031 - mae: 0.2031 - val_loss: 0.1877 - val_mae: 0.1877\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.2014 - mae: 0.2014 - val_loss: 0.1851 - val_mae: 0.1851\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1994 - mae: 0.1994 - val_loss: 0.1822 - val_mae: 0.1822\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1977 - mae: 0.1977 - val_loss: 0.1800 - val_mae: 0.1800\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1969 - mae: 0.1969 - val_loss: 0.1794 - val_mae: 0.1794\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1951 - mae: 0.1951 - val_loss: 0.1794 - val_mae: 0.1794\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.1939 - mae: 0.1939 - val_loss: 0.1785 - val_mae: 0.1785\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.1926 - mae: 0.1926 - val_loss: 0.1773 - val_mae: 0.1773\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1917 - mae: 0.1917 - val_loss: 0.1756 - val_mae: 0.1756\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1901 - mae: 0.1901 - val_loss: 0.1749 - val_mae: 0.1749\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1890 - mae: 0.1890 - val_loss: 0.1742 - val_mae: 0.1742\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1882 - mae: 0.1882 - val_loss: 0.1733 - val_mae: 0.1733\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1870 - mae: 0.1870 - val_loss: 0.1720 - val_mae: 0.1720\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1859 - mae: 0.1859 - val_loss: 0.1719 - val_mae: 0.1719\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1848 - mae: 0.1848 - val_loss: 0.1723 - val_mae: 0.1723\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 139ms/step - loss: 0.1839 - mae: 0.1839 - val_loss: 0.1718 - val_mae: 0.1718\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.1840 - mae: 0.1840 - val_loss: 0.1700 - val_mae: 0.1700\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1822 - mae: 0.1822 - val_loss: 0.1686 - val_mae: 0.1686\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.1821 - mae: 0.1821 - val_loss: 0.1690 - val_mae: 0.1690\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1808 - mae: 0.1808 - val_loss: 0.1683 - val_mae: 0.1683\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1801 - mae: 0.1801 - val_loss: 0.1678 - val_mae: 0.1678\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.1803 - mae: 0.1803 - val_loss: 0.1666 - val_mae: 0.1666\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1785 - mae: 0.1785 - val_loss: 0.1657 - val_mae: 0.1657\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.1785 - mae: 0.1785 - val_loss: 0.1655 - val_mae: 0.1655\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1784 - mae: 0.1784 - val_loss: 0.1659 - val_mae: 0.1659\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1788 - mae: 0.1788 - val_loss: 0.1659 - val_mae: 0.1659\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1773 - mae: 0.1773 - val_loss: 0.1656 - val_mae: 0.1656\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1763 - mae: 0.1763 - val_loss: 0.1654 - val_mae: 0.1654\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1757 - mae: 0.1757 - val_loss: 0.1649 - val_mae: 0.1649\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.1754 - mae: 0.1754 - val_loss: 0.1642 - val_mae: 0.1642\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.1746 - mae: 0.1746 - val_loss: 0.1642 - val_mae: 0.1642\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.1740 - mae: 0.1740 - val_loss: 0.1637 - val_mae: 0.1637\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1739 - mae: 0.1739 - val_loss: 0.1623 - val_mae: 0.1623\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1732 - mae: 0.1732 - val_loss: 0.1617 - val_mae: 0.1617\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1728 - mae: 0.1728 - val_loss: 0.1612 - val_mae: 0.1612\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1720 - mae: 0.1720 - val_loss: 0.1604 - val_mae: 0.1604\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1716 - mae: 0.1716 - val_loss: 0.1595 - val_mae: 0.1595\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1709 - mae: 0.1709 - val_loss: 0.1586 - val_mae: 0.1586\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1706 - mae: 0.1706 - val_loss: 0.1581 - val_mae: 0.1581\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1706 - mae: 0.1706 - val_loss: 0.1579 - val_mae: 0.1579\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1690 - mae: 0.1690 - val_loss: 0.1577 - val_mae: 0.1577\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1699 - mae: 0.1699 - val_loss: 0.1576 - val_mae: 0.1576\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1694 - mae: 0.1694 - val_loss: 0.1561 - val_mae: 0.1561\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1687 - mae: 0.1687 - val_loss: 0.1558 - val_mae: 0.1558\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.1674 - mae: 0.1674 - val_loss: 0.1565 - val_mae: 0.1565\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.1663 - mae: 0.1663 - val_loss: 0.1557 - val_mae: 0.1557\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1657 - mae: 0.1657 - val_loss: 0.1546 - val_mae: 0.1546\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1654 - mae: 0.1654 - val_loss: 0.1527 - val_mae: 0.1527\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.1643 - mae: 0.1643 - val_loss: 0.1513 - val_mae: 0.1513\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 154ms/step - loss: 0.1637 - mae: 0.1637 - val_loss: 0.1504 - val_mae: 0.1504\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.1632 - mae: 0.1632 - val_loss: 0.1502 - val_mae: 0.1502\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1623 - mae: 0.1623 - val_loss: 0.1506 - val_mae: 0.1506\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1631 - mae: 0.1631 - val_loss: 0.1506 - val_mae: 0.1506\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1614 - mae: 0.1614 - val_loss: 0.1510 - val_mae: 0.1510\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1616 - mae: 0.1616 - val_loss: 0.1508 - val_mae: 0.1508\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1609 - mae: 0.1609 - val_loss: 0.1490 - val_mae: 0.1490\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1597 - mae: 0.1597 - val_loss: 0.1481 - val_mae: 0.1481\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1597 - mae: 0.1597 - val_loss: 0.1479 - val_mae: 0.1479\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1587 - mae: 0.1587 - val_loss: 0.1475 - val_mae: 0.1475\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1582 - mae: 0.1582 - val_loss: 0.1456 - val_mae: 0.1456\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.1574 - mae: 0.1574 - val_loss: 0.1446 - val_mae: 0.1446\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.1575 - mae: 0.1575 - val_loss: 0.1452 - val_mae: 0.1452\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.1569 - mae: 0.1569 - val_loss: 0.1468 - val_mae: 0.1468\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.1577 - mae: 0.1577 - val_loss: 0.1455 - val_mae: 0.1455\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1559 - mae: 0.1559 - val_loss: 0.1437 - val_mae: 0.1437\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1572 - mae: 0.1572 - val_loss: 0.1422 - val_mae: 0.1422\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1550 - mae: 0.1550 - val_loss: 0.1431 - val_mae: 0.1431\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1560 - mae: 0.1560 - val_loss: 0.1447 - val_mae: 0.1447\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1560 - mae: 0.1560 - val_loss: 0.1415 - val_mae: 0.1415\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.1525 - mae: 0.1525 - val_loss: 0.1416 - val_mae: 0.1416\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1559 - mae: 0.1559 - val_loss: 0.1404 - val_mae: 0.1404\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1525 - mae: 0.1525 - val_loss: 0.1420 - val_mae: 0.1420\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1533 - mae: 0.1533 - val_loss: 0.1413 - val_mae: 0.1413\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1532 - mae: 0.1532 - val_loss: 0.1380 - val_mae: 0.1380\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1520 - mae: 0.1520 - val_loss: 0.1382 - val_mae: 0.1382\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1531 - mae: 0.1531 - val_loss: 0.1380 - val_mae: 0.1380\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1502 - mae: 0.1502 - val_loss: 0.1383 - val_mae: 0.1383\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1499 - mae: 0.1499 - val_loss: 0.1374 - val_mae: 0.1374\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1486 - mae: 0.1486 - val_loss: 0.1370 - val_mae: 0.1370\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 0.1500 - mae: 0.1500 - val_loss: 0.1368 - val_mae: 0.1368\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1484 - mae: 0.1484 - val_loss: 0.1373 - val_mae: 0.1373\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1479 - mae: 0.1479 - val_loss: 0.1369 - val_mae: 0.1369\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1484 - mae: 0.1484 - val_loss: 0.1349 - val_mae: 0.1349\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1465 - mae: 0.1465 - val_loss: 0.1343 - val_mae: 0.1343\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1457 - mae: 0.1457 - val_loss: 0.1346 - val_mae: 0.1346\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1451 - mae: 0.1451 - val_loss: 0.1344 - val_mae: 0.1344\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1457 - mae: 0.1457 - val_loss: 0.1325 - val_mae: 0.1325\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1457 - mae: 0.1457 - val_loss: 0.1320 - val_mae: 0.1320\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1446 - mae: 0.1446 - val_loss: 0.1317 - val_mae: 0.1317\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1432 - mae: 0.1432 - val_loss: 0.1322 - val_mae: 0.1322\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1435 - mae: 0.1435 - val_loss: 0.1311 - val_mae: 0.1311\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1422 - mae: 0.1422 - val_loss: 0.1299 - val_mae: 0.1299\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1417 - mae: 0.1417 - val_loss: 0.1290 - val_mae: 0.1290\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1421 - mae: 0.1421 - val_loss: 0.1284 - val_mae: 0.1284\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1425 - mae: 0.1425 - val_loss: 0.1287 - val_mae: 0.1287\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1424 - mae: 0.1424 - val_loss: 0.1278 - val_mae: 0.1278\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.1400 - mae: 0.1400 - val_loss: 0.1270 - val_mae: 0.1270\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.1398 - mae: 0.1398 - val_loss: 0.1270 - val_mae: 0.1270\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1388 - mae: 0.1388 - val_loss: 0.1261 - val_mae: 0.1261\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1385 - mae: 0.1385 - val_loss: 0.1249 - val_mae: 0.1249\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1384 - mae: 0.1384 - val_loss: 0.1248 - val_mae: 0.1248\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.1379 - mae: 0.1379 - val_loss: 0.1237 - val_mae: 0.1237\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1373 - mae: 0.1373 - val_loss: 0.1233 - val_mae: 0.1233\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1369 - mae: 0.1369 - val_loss: 0.1234 - val_mae: 0.1234\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.1358 - mae: 0.1358 - val_loss: 0.1229 - val_mae: 0.1229\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1357 - mae: 0.1357 - val_loss: 0.1213 - val_mae: 0.1213\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 0.1347 - mae: 0.1347 - val_loss: 0.1207 - val_mae: 0.1207\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.1349 - mae: 0.1349 - val_loss: 0.1209 - val_mae: 0.1209\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1339 - mae: 0.1339 - val_loss: 0.1194 - val_mae: 0.1194\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1333 - mae: 0.1333 - val_loss: 0.1190 - val_mae: 0.1190\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1326 - mae: 0.1326 - val_loss: 0.1193 - val_mae: 0.1193\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1318 - mae: 0.1318 - val_loss: 0.1193 - val_mae: 0.1193\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1315 - mae: 0.1315 - val_loss: 0.1177 - val_mae: 0.1177\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1311 - mae: 0.1311 - val_loss: 0.1162 - val_mae: 0.1162\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1307 - mae: 0.1307 - val_loss: 0.1155 - val_mae: 0.1155\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1305 - mae: 0.1305 - val_loss: 0.1167 - val_mae: 0.1167\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1290 - mae: 0.1290 - val_loss: 0.1162 - val_mae: 0.1162\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1299 - mae: 0.1299 - val_loss: 0.1157 - val_mae: 0.1157\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1289 - mae: 0.1289 - val_loss: 0.1154 - val_mae: 0.1154\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1274 - mae: 0.1274 - val_loss: 0.1118 - val_mae: 0.1118\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.1275 - mae: 0.1275 - val_loss: 0.1111 - val_mae: 0.1111\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.1281 - mae: 0.1281 - val_loss: 0.1112 - val_mae: 0.1112\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.1255 - mae: 0.1255 - val_loss: 0.1140 - val_mae: 0.1140\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.1267 - mae: 0.1267 - val_loss: 0.1111 - val_mae: 0.1111\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1241 - mae: 0.1241 - val_loss: 0.1094 - val_mae: 0.1094\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1254 - mae: 0.1254 - val_loss: 0.1074 - val_mae: 0.1074\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1236 - mae: 0.1236 - val_loss: 0.1076 - val_mae: 0.1076\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1243 - mae: 0.1243 - val_loss: 0.1075 - val_mae: 0.1075\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1228 - mae: 0.1228 - val_loss: 0.1071 - val_mae: 0.1071\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1217 - mae: 0.1217 - val_loss: 0.1074 - val_mae: 0.1074\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1216 - mae: 0.1216 - val_loss: 0.1086 - val_mae: 0.1086\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1204 - mae: 0.1204 - val_loss: 0.1059 - val_mae: 0.1059\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1201 - mae: 0.1201 - val_loss: 0.1037 - val_mae: 0.1037\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 0.1191 - mae: 0.1191 - val_loss: 0.1045 - val_mae: 0.1045\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1186 - mae: 0.1186 - val_loss: 0.1051 - val_mae: 0.1051\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1177 - mae: 0.1177 - val_loss: 0.1032 - val_mae: 0.1032\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1177 - mae: 0.1177 - val_loss: 0.1011 - val_mae: 0.1011\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1171 - mae: 0.1171 - val_loss: 0.1016 - val_mae: 0.1016\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1164 - mae: 0.1164 - val_loss: 0.1014 - val_mae: 0.1014\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1152 - mae: 0.1152 - val_loss: 0.1012 - val_mae: 0.1012\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.1150 - mae: 0.1150 - val_loss: 0.1012 - val_mae: 0.1012\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.1148 - mae: 0.1148 - val_loss: 0.0963 - val_mae: 0.0963\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.1148 - mae: 0.1148 - val_loss: 0.0948 - val_mae: 0.0948\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.1147 - mae: 0.1147 - val_loss: 0.0956 - val_mae: 0.0956\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1132 - mae: 0.1132 - val_loss: 0.1006 - val_mae: 0.1006\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1131 - mae: 0.1131 - val_loss: 0.0987 - val_mae: 0.0987\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1116 - mae: 0.1116 - val_loss: 0.0952 - val_mae: 0.0952\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1109 - mae: 0.1109 - val_loss: 0.0939 - val_mae: 0.0939\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1099 - mae: 0.1099 - val_loss: 0.0946 - val_mae: 0.0946\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.1095 - mae: 0.1095 - val_loss: 0.0960 - val_mae: 0.0960\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.1091 - mae: 0.1091 - val_loss: 0.0944 - val_mae: 0.0944\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.1084 - mae: 0.1084 - val_loss: 0.0932 - val_mae: 0.0932\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1086 - mae: 0.1086 - val_loss: 0.0910 - val_mae: 0.0910\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1074 - mae: 0.1074 - val_loss: 0.0916 - val_mae: 0.0916\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.1072 - mae: 0.1072 - val_loss: 0.0928 - val_mae: 0.0928\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.1070 - mae: 0.1070 - val_loss: 0.0916 - val_mae: 0.0916\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1059 - mae: 0.1059 - val_loss: 0.0861 - val_mae: 0.0861\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1057 - mae: 0.1057 - val_loss: 0.0853 - val_mae: 0.0853\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 0.1051 - mae: 0.1051 - val_loss: 0.0867 - val_mae: 0.0867\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.1041 - mae: 0.1041 - val_loss: 0.0900 - val_mae: 0.0900\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1025 - mae: 0.1025 - val_loss: 0.0866 - val_mae: 0.0866\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1034 - mae: 0.1034 - val_loss: 0.0840 - val_mae: 0.0840\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1031 - mae: 0.1031 - val_loss: 0.0852 - val_mae: 0.0852\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1012 - mae: 0.1012 - val_loss: 0.0869 - val_mae: 0.0869\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1013 - mae: 0.1013 - val_loss: 0.0849 - val_mae: 0.0849\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1003 - mae: 0.1003 - val_loss: 0.0819 - val_mae: 0.0819\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0992 - mae: 0.0992 - val_loss: 0.0828 - val_mae: 0.0828\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0998 - mae: 0.0998 - val_loss: 0.0810 - val_mae: 0.0810\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0983 - mae: 0.0983 - val_loss: 0.0832 - val_mae: 0.0832\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0989 - mae: 0.0989 - val_loss: 0.0828 - val_mae: 0.0828\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0976 - mae: 0.0976 - val_loss: 0.0802 - val_mae: 0.0802\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0979 - mae: 0.0979 - val_loss: 0.0796 - val_mae: 0.0796\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0972 - mae: 0.0972 - val_loss: 0.0801 - val_mae: 0.0801\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0979 - mae: 0.0979 - val_loss: 0.0798 - val_mae: 0.0798\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0963 - mae: 0.0963 - val_loss: 0.0783 - val_mae: 0.0783\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0972 - mae: 0.0972 - val_loss: 0.0775 - val_mae: 0.0775\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0958 - mae: 0.0958 - val_loss: 0.0793 - val_mae: 0.0793\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0965 - mae: 0.0965 - val_loss: 0.0788 - val_mae: 0.0788\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0958 - mae: 0.0958 - val_loss: 0.0772 - val_mae: 0.0772\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0958 - mae: 0.0958 - val_loss: 0.0767 - val_mae: 0.0767\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0959 - mae: 0.0959 - val_loss: 0.0788 - val_mae: 0.0788\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0959 - mae: 0.0959 - val_loss: 0.0774 - val_mae: 0.0774\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 0.0962 - mae: 0.0962 - val_loss: 0.0751 - val_mae: 0.0751\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0950 - mae: 0.0950 - val_loss: 0.0755 - val_mae: 0.0755\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0961 - mae: 0.0961 - val_loss: 0.0733 - val_mae: 0.0733\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0957 - mae: 0.0957 - val_loss: 0.0757 - val_mae: 0.0757\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0957 - mae: 0.0957 - val_loss: 0.0799 - val_mae: 0.0799\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0971 - mae: 0.0971 - val_loss: 0.0780 - val_mae: 0.0780\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0956 - mae: 0.0956 - val_loss: 0.0743 - val_mae: 0.0743\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0952 - mae: 0.0952 - val_loss: 0.0734 - val_mae: 0.0734\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0938 - mae: 0.0938 - val_loss: 0.0744 - val_mae: 0.0744\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0944 - mae: 0.0944 - val_loss: 0.0727 - val_mae: 0.0727\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0937 - mae: 0.0937 - val_loss: 0.0722 - val_mae: 0.0722\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0930 - mae: 0.0930 - val_loss: 0.0739 - val_mae: 0.0739\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0933 - mae: 0.0933 - val_loss: 0.0748 - val_mae: 0.0748\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0928 - mae: 0.0928 - val_loss: 0.0732 - val_mae: 0.0732\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0924 - mae: 0.0924 - val_loss: 0.0710 - val_mae: 0.0710\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0933 - mae: 0.0933 - val_loss: 0.0710 - val_mae: 0.0710\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0927 - mae: 0.0927 - val_loss: 0.0724 - val_mae: 0.0724\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0923 - mae: 0.0923 - val_loss: 0.0711 - val_mae: 0.0711\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0921 - mae: 0.0921 - val_loss: 0.0712 - val_mae: 0.0712\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0923 - mae: 0.0923 - val_loss: 0.0720 - val_mae: 0.0720\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0913 - mae: 0.0913 - val_loss: 0.0703 - val_mae: 0.0703\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0915 - mae: 0.0915 - val_loss: 0.0700 - val_mae: 0.0700\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0920 - mae: 0.0920 - val_loss: 0.0700 - val_mae: 0.0700\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 151ms/step - loss: 0.0914 - mae: 0.0914 - val_loss: 0.0690 - val_mae: 0.0690\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0907 - mae: 0.0907 - val_loss: 0.0696 - val_mae: 0.0696\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0908 - mae: 0.0908 - val_loss: 0.0719 - val_mae: 0.0719\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0911 - mae: 0.0911 - val_loss: 0.0705 - val_mae: 0.0705\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0907 - mae: 0.0907 - val_loss: 0.0698 - val_mae: 0.0698\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0911 - mae: 0.0911 - val_loss: 0.0684 - val_mae: 0.0684\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0908 - mae: 0.0908 - val_loss: 0.0664 - val_mae: 0.0664\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0900 - mae: 0.0900 - val_loss: 0.0678 - val_mae: 0.0678\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0905 - mae: 0.0905 - val_loss: 0.0677 - val_mae: 0.0677\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0895 - mae: 0.0895 - val_loss: 0.0686 - val_mae: 0.0686\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0908 - mae: 0.0908 - val_loss: 0.0704 - val_mae: 0.0704\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0907 - mae: 0.0907 - val_loss: 0.0708 - val_mae: 0.0708\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.0894 - mae: 0.0894 - val_loss: 0.0682 - val_mae: 0.0682\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.0902 - mae: 0.0902 - val_loss: 0.0656 - val_mae: 0.0656\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 0.0890 - mae: 0.0890 - val_loss: 0.0681 - val_mae: 0.0681\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 0.0903 - mae: 0.0903 - val_loss: 0.0668 - val_mae: 0.0668\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0894 - mae: 0.0894 - val_loss: 0.0680 - val_mae: 0.0680\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0909 - mae: 0.0909 - val_loss: 0.0680 - val_mae: 0.0680\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0890 - mae: 0.0890 - val_loss: 0.0679 - val_mae: 0.0679\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0883 - mae: 0.0883 - val_loss: 0.0642 - val_mae: 0.0642\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0890 - mae: 0.0890 - val_loss: 0.0626 - val_mae: 0.0626\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 0.0885 - mae: 0.0885 - val_loss: 0.0656 - val_mae: 0.0656\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0889 - mae: 0.0889 - val_loss: 0.0654 - val_mae: 0.0654\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0877 - mae: 0.0877 - val_loss: 0.0655 - val_mae: 0.0655\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0876 - mae: 0.0876 - val_loss: 0.0647 - val_mae: 0.0647\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0874 - mae: 0.0874 - val_loss: 0.0645 - val_mae: 0.0645\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0874 - mae: 0.0874 - val_loss: 0.0638 - val_mae: 0.0638\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0867 - mae: 0.0867 - val_loss: 0.0648 - val_mae: 0.0648\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0876 - mae: 0.0876 - val_loss: 0.0646 - val_mae: 0.0646\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.0866 - mae: 0.0866 - val_loss: 0.0654 - val_mae: 0.0654\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0871 - mae: 0.0871 - val_loss: 0.0640 - val_mae: 0.0640\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0863 - mae: 0.0863 - val_loss: 0.0623 - val_mae: 0.0623\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0865 - mae: 0.0865 - val_loss: 0.0609 - val_mae: 0.0609\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0866 - mae: 0.0866 - val_loss: 0.0623 - val_mae: 0.0623\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0863 - mae: 0.0863 - val_loss: 0.0633 - val_mae: 0.0633\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0854 - mae: 0.0854 - val_loss: 0.0647 - val_mae: 0.0647\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0855 - mae: 0.0855 - val_loss: 0.0635 - val_mae: 0.0635\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0850 - mae: 0.0850 - val_loss: 0.0608 - val_mae: 0.0608\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0853 - mae: 0.0853 - val_loss: 0.0601 - val_mae: 0.0601\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0861 - mae: 0.0861 - val_loss: 0.0603 - val_mae: 0.0603\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0853 - mae: 0.0853 - val_loss: 0.0643 - val_mae: 0.0643\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 0.0860 - mae: 0.0860 - val_loss: 0.0630 - val_mae: 0.0630\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0865 - mae: 0.0865 - val_loss: 0.0631 - val_mae: 0.0631\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0850 - mae: 0.0850 - val_loss: 0.0670 - val_mae: 0.0670\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0892 - mae: 0.0892 - val_loss: 0.0599 - val_mae: 0.0599\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0863 - mae: 0.0863 - val_loss: 0.0616 - val_mae: 0.0616\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0859 - mae: 0.0859 - val_loss: 0.0594 - val_mae: 0.0594\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0851 - mae: 0.0851 - val_loss: 0.0608 - val_mae: 0.0608\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0836 - mae: 0.0836 - val_loss: 0.0641 - val_mae: 0.0641\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0858 - mae: 0.0858 - val_loss: 0.0661 - val_mae: 0.0661\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0849 - mae: 0.0849 - val_loss: 0.0651 - val_mae: 0.0651\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0846 - mae: 0.0846 - val_loss: 0.0612 - val_mae: 0.0612\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0846 - mae: 0.0846 - val_loss: 0.0600 - val_mae: 0.0600\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0843 - mae: 0.0843 - val_loss: 0.0598 - val_mae: 0.0598\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0843 - mae: 0.0843 - val_loss: 0.0585 - val_mae: 0.0585\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0841 - mae: 0.0841 - val_loss: 0.0593 - val_mae: 0.0593\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0836 - mae: 0.0836 - val_loss: 0.0605 - val_mae: 0.0605\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0838 - mae: 0.0838 - val_loss: 0.0595 - val_mae: 0.0595\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 0.0841 - mae: 0.0841 - val_loss: 0.0601 - val_mae: 0.0601\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0829 - mae: 0.0829 - val_loss: 0.0575 - val_mae: 0.0575\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0848 - mae: 0.0848 - val_loss: 0.0580 - val_mae: 0.0580\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0828 - mae: 0.0828 - val_loss: 0.0624 - val_mae: 0.0624\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0844 - mae: 0.0844 - val_loss: 0.0566 - val_mae: 0.0566\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0831 - mae: 0.0831 - val_loss: 0.0577 - val_mae: 0.0577\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0836 - mae: 0.0836 - val_loss: 0.0574 - val_mae: 0.0574\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0831 - mae: 0.0831 - val_loss: 0.0575 - val_mae: 0.0575\n"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs=500,\n",
        "                    batch_size=100,\n",
        "                    validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6vgAvdUerd8",
        "outputId": "1f2bad6c-7b73-4fb8-d940-263798e4b8fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\akhil\\AppData\\Local\\Temp\\tmpfvazj_p5\\assets\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "4872"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert Keras model to a tflite model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open(tflite_model_name + '.tflite', 'wb').write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "JECNPwW7ewnX"
      },
      "outputs": [],
      "source": [
        "# Function: Convert some hex value into an array for C programming\n",
        "def hex_to_c_array(hex_data, var_name):\n",
        "\n",
        "  c_str = ''\n",
        "\n",
        "  # Create header guard\n",
        "  c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
        "  c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
        "\n",
        "  # Add array length at top of file\n",
        "  c_str += '\\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
        "\n",
        "  # Declare C variable\n",
        "  c_str += 'unsigned char ' + var_name + '[] = {'\n",
        "  hex_array = []\n",
        "  for i, val in enumerate(hex_data) :\n",
        "\n",
        "    # Construct string from hex\n",
        "    hex_str = format(val, '#04x')\n",
        "\n",
        "    # Add formatting so each line stays within 80 characters\n",
        "    if (i + 1) < len(hex_data):\n",
        "      hex_str += ','\n",
        "    if (i + 1) % 12 == 0:\n",
        "      hex_str += '\\n '\n",
        "    hex_array.append(hex_str)\n",
        "\n",
        "  # Add closing brace\n",
        "  c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
        "\n",
        "  # Close out header guard\n",
        "  c_str += '#endif //' + var_name.upper() + '_H'\n",
        "\n",
        "  return c_str\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "N8L7GDHfezu8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Write TFLite model to a C source (or header) file\n",
        "with open(c_model_name + '.h', 'w') as file:\n",
        "  file.write(hex_to_c_array(tflite_model, c_model_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j_oxbQie5ok"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
